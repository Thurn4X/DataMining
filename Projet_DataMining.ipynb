{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99853a304163fca",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b50da64db3d6205",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import gdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58977e44dd01fde",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Téléchargement du dataset\n",
    "Téléchargement de 800 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# URL de téléchargement direct Google Drive\n",
    "# pour le gros dataset non tagged\n",
    "url = 'https://drive.google.com/uc?id=16rYRrxUXpGyPWVq5uhgYzNlZd6hsGX7-'\n",
    "# pour le petit dataset pokemon\n",
    "# url = 'https://drive.google.com/uc?id=1yfy6XXv0VikxR8xTuz-xQts_MmGWRDUy'\n",
    "# Chemin de destination\n",
    "output = 'dataset.zip'\n",
    "\n",
    "# Télécharge le fichier depuis l'URL\n",
    "gdown.download(url, output, quiet=False)\n",
    "\n",
    "# Décompresse le fichier dans le dossier 'img'\n",
    "with zipfile.ZipFile(output, 'r') as zip_ref:\n",
    "    zip_ref.extractall('images')\n",
    "# Supprime le fichier zip si désiré\n",
    "os.remove(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c324890478dcc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Création du fichier de métadonnées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580c20f360bfba9f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install pillow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cc63d4b0a33b97",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ExifTags\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2051b7444dd34e5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_dominant_color(image_path, n_clusters=2):\n",
    "    img = Image.open(image_path).convert('RGBA')  # Convertir en RGBA\n",
    "    img = img.resize((50, 50))  # Optionnel: Redimensionner\n",
    "\n",
    "    # Convertir l'image RGBA en une array numpy, ignorer les pixels complètement transparents\n",
    "    numarray = np.array(img)\n",
    "    numarray = numarray[:, :, :3][numarray[:, :, 3] > 0]  # Ignorer les pixels transparents\n",
    "\n",
    "    clusters = MiniBatchKMeans(n_clusters=n_clusters)\n",
    "    clusters.fit(numarray)\n",
    "\n",
    "    counts = np.bincount(clusters.labels_)\n",
    "    most_frequent = clusters.cluster_centers_[counts.argmax()]\n",
    "\n",
    "    return tuple(int(c) for c in most_frequent)\n",
    "\n",
    "\n",
    "# Fonction pour avoir l’orientation de l’image\n",
    "def get_image_orientation(img):\n",
    "    if img.width > img.height:\n",
    "        return \"paysage\"\n",
    "    elif img.width < img.height:\n",
    "        return \"portrait\"\n",
    "    else:\n",
    "        return \"carre\"\n",
    "\n",
    "\n",
    "# Fonction pour extraire les données Exif\n",
    "def get_exif_data(img):\n",
    "    exif_data = {}\n",
    "    raw_exif = img._getexif()\n",
    "    if raw_exif:\n",
    "        for tag, value in raw_exif.items():\n",
    "            decoded_tag = ExifTags.TAGS.get(tag, tag)\n",
    "            exif_data[decoded_tag] = value\n",
    "    return exif_data\n",
    "\n",
    "# Chemin vers le dossier d'images et le fichier de métadonnées\n",
    "images_path = 'images/unsplash-images-collection'\n",
    "metadata_file = 'image_metadata.json'\n",
    "metadata = []\n",
    "\n",
    "for image_file in os.listdir(images_path):\n",
    "    image_path = os.path.join(images_path, image_file)\n",
    "\n",
    "    img = Image.open(image_path)\n",
    "    # Extraction des données Exif\n",
    "    exif_data = get_exif_data(img)\n",
    "    dominant_color = find_dominant_color(image_path)  # Trouver la couleur dominante\n",
    "\n",
    "    metadata.append({\n",
    "        \"nom\": image_file,\n",
    "        \"taille\": img.size,\n",
    "        \"format\": img.format,\n",
    "        \"orientation\": get_image_orientation(img),\n",
    "        \"exif\": exif_data,  # Ajoutez les données Exif ici\n",
    "        \"couleur_dominante\": dominant_color,  # Ajouter la couleur dominante aux métadonnées\n",
    "\n",
    "        \"tags\": [],\n",
    "        \"favori\": \"n/a\"\n",
    "    })\n",
    "\n",
    "if metadata:\n",
    "    with open(metadata_file, 'w') as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "    print(\"Métadonnées enregistrées.\")\n",
    "else:\n",
    "    print(\"Aucune métadonnée à enregistrer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d89ee89ce4eab",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Création automatisée de tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a84b9099e7a863",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Version CPU\n",
    "Compatible avec toutes les configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2ea75464cf7b6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4085ee6bd6931cd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Version GPU\n",
    "Pour les utilisateurs Linux disposant d'un GPU NVIDIA uniquement.\n",
    "Il est nécessaire d'avoir installé les drivers CUDA et cuDNN au préalable.\n",
    "\n",
    "Pour les utilisateurs de Windows, il est possible d'installer TensorFlow en mode GPU avec Anaconda.\n",
    "Installer cudatoolkit=11.2 cudnn=8.1.0\n",
    "Une fois installé, installer tensorflow=2.10 avec pip et sentence-transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1805e7c28ea1e95c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if os.name == 'posix':\n",
    "    !pip install tensorflow[and-cuda]\n",
    "    !pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc10df9b9a305de",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bf1477b70d2903",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_tags(img_path, model):\n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    preds = model.predict(x)\n",
    "    # Retourne une liste des top 3 tags prédits\n",
    "    return [tag[1] for tag in decode_predictions(preds, top=1)[0]]\n",
    "\n",
    "def associated_theme(tag,model_language,theme_embeddings):\n",
    "        # Charger le modèle de transformation de phrases\n",
    "\n",
    "    tag_embedding = model_language.encode([tag], convert_to_tensor=True)\n",
    "    max_similarity = -1\n",
    "    assigned_theme = \"other\"\n",
    "    for theme, theme_embedding in theme_embeddings.items():\n",
    "        similarity = util.pytorch_cos_sim(tag_embedding, theme_embedding).max()\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            assigned_theme = theme\n",
    "    return assigned_theme\n",
    "\n",
    "# Charger les métadonnées existantes\n",
    "def load_metadata():\n",
    "    metadata_file = 'image_metadata.json'\n",
    "    with open(metadata_file, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "# Chemin vers le dossier d'images et le fichier de métadonnées\n",
    "image_folder = 'images/unsplash-images-collection'\n",
    "\n",
    "\"\"\"Mise à jour des métadonnées avec des tags prédits pour chaque image.\"\"\"\n",
    "metadata = load_metadata()\n",
    "metadata_file = 'image_metadata.json'\n",
    "image_files = [file for file in os.listdir(image_folder) if\n",
    "               file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif'))]\n",
    "model = InceptionV3(weights='imagenet')\n",
    "\n",
    "model_language = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Thèmes et mots-clés correspondants\n",
    "themes = {\n",
    "    \"nature\": [\"forest\",\"greenhouse\",\"boathouse\", \"river\", \"mountain\", \"sky\", \"lake\", \"ocean\", \"canoe\", \"geyser\", \"flower\", \"maze\",\"alp\",\"dam\",\"snowplow\", \"desert\",\n",
    "               \"valley\",\"hay\",\"bubble\"],\n",
    "    \"sports\": [\"mountain_bike\",\"soccer\", \"basketball\", \"tennis\", \"ball\", \"running\", \"swimming\", \"cycling\"],\n",
    "    \"art\": [\"vase\",\"painting\", \"sculpture\", \"drawing\", \"museum\", \"gallery\", \"street art\",\"dome\"],\n",
    "    \"animal\": [\"animal\", \"dog\", \"cat\", \"bird\", \"fish\", \"wildlife\",\"honeycomb\",],\n",
    "    \"object\": [\"table\", \"balloon\", \"object\", \"chair\", \"lamp\", \"computer\",\"basket\"],\n",
    "    \"food\": [\"hotdog\",\"food\", \"vegetable\", \"fruit\", \"meal\", \"dessert\", \"drink\",\"plate\",\"matchstick\",\"cup\",\"parachute\",\"rotisserie\",\"barometer\"],\n",
    "    \"clothes\": [\"shirt\", \"cloak\", \"sock\", \"pants\", \"dress\", \"hat\", \"shoes\", \"stockings\"],\n",
    "    \"transportation\": [\"bridge\",\"car\", \"train\", \"airplane\", \"bike\", \"boat\", \"road\", \"highway\"],\n",
    "    \"urban\": [\"street\", \"alley\", \"urban\", \"city life\", \"market\", \"park\",\"window\",\"uniform\",\"solar_dish\",\"fence\",\"stupa\",\"palace\"],\n",
    "    # Add more themes as needed\n",
    "}\n",
    "\n",
    "# Embeddings pour les thèmes\n",
    "theme_embeddings = {theme: model_language.encode(keywords, convert_to_tensor=True) for theme, keywords in themes.items()}\n",
    "\n",
    "for image_name in image_files:\n",
    "    image_path = os.path.join(image_folder, image_name)\n",
    "    # Générer des tags prédits pour l'image\n",
    "    predicted_tags = predict_tags(image_path, model)\n",
    "    predicted_theme = associated_theme(predicted_tags[0],model_language,theme_embeddings)\n",
    "    # Trouver l'entrée correspondante dans les métadonnées et mettre à jour les tags\n",
    "    for entry in metadata:\n",
    "        if entry[\"nom\"] == image_name:\n",
    "            entry[\"tags\"] = predicted_theme\n",
    "            break\n",
    "\n",
    "# Sauvegarder les métadonnées mises à jour\n",
    "with open(metadata_file, 'w') as f:\n",
    "    json.dump(metadata, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907ae9979c2873fd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Séléction des images favorites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b86c05c6880d96",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ff5b35eac6bfcd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import GridspecLayout\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5abe09b51d297b6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "for file in listdir(\"images/unsplash-images-collection\")[:50]:\n",
    "    images.append(\"images/unsplash-images-collection/\" + file)\n",
    "\n",
    "checkboxes = [widgets.Checkbox(value=False, description='Favorite') for _ in range(len(images))]\n",
    "\n",
    "# Create the GridspecLayout widget\n",
    "layout = GridspecLayout(n_columns=4, n_rows=len(images)//2, width='1000px')\n",
    "for i, (img, checkbox) in enumerate(zip(images, checkboxes)):\n",
    "  file = open(img, \"rb\")\n",
    "  image = file.read()\n",
    "  image_widget = widgets.Image(\n",
    "    value=image,\n",
    "    format='png',\n",
    "    width=100,\n",
    "    height=100,\n",
    "  )\n",
    "  layout[i//2, 0+((i%2)*2)] = image_widget\n",
    "  layout[i//2, 1+((i%2)*2)] = checkbox\n",
    "\n",
    "# Button to get selected images\n",
    "button = widgets.Button(description=\"Select\")\n",
    "\n",
    "# Output widget to display selected images\n",
    "output = widgets.Output()\n",
    "\n",
    "def load_metadata():\n",
    "    metadata_file = 'image_metadata.json'\n",
    "    with open(metadata_file, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def favori(paths):\n",
    "    metadata = load_metadata()\n",
    "    for entry in metadata:\n",
    "        if entry[\"nom\"] in paths:\n",
    "            entry[\"favori\"] = \"yes\"\n",
    "    with open(metadata_file, 'w') as f:\n",
    "        json.dump(metadata, f, indent=5)\n",
    "\n",
    "def not_favori(paths):\n",
    "    metadata = load_metadata()\n",
    "    for entry in metadata:\n",
    "        if entry[\"nom\"] in paths:\n",
    "            entry[\"favori\"] = \"no\"\n",
    "    with open(metadata_file, 'w') as f:\n",
    "        json.dump(metadata, f, indent=5)\n",
    "\n",
    "# Function to get selected images\n",
    "def get_selected_images(btn):\n",
    "    selected_paths = [images[i][34:] for i, checkbox in enumerate(checkboxes) if checkbox.value]\n",
    "    not_selected_paths = [images[i][34:] for i, checkbox in enumerate(checkboxes) if not checkbox.value]\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        favori(selected_paths)\n",
    "        not_favori(not_selected_paths)\n",
    "        print(\"Préférences enregistrées.\")\n",
    "\n",
    "# Link button click event to function\n",
    "button.on_click(get_selected_images)\n",
    "\n",
    "# Display the layout and button\n",
    "display(layout, button, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d7b2fe0eb4df6c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Création du dataset final"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!pip install pandas"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b054d3702d21495",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a22ab260ff90c3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2e18fb13618fb0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"image_metadata.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "\n",
    "dataframe = pd.json_normalize(data)\n",
    "dataframe['aire_image'] = dataframe['taille'].apply(lambda x: x[0] * x[1])\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "tags_encoded = mlb.fit_transform(dataframe['tags'])\n",
    "tags_df = pd.DataFrame(tags_encoded, columns=mlb.classes_)\n",
    "\n",
    "format_df = pd.get_dummies(dataframe['format'], prefix='format')\n",
    "orientation_df = pd.get_dummies(dataframe['orientation'], prefix='orientation')\n",
    "\n",
    "dataframe['dominant_color_r'] = dataframe['couleur_dominante'].apply(\n",
    "    lambda x: x[0] if isinstance(x, list) else 0)\n",
    "dataframe['dominant_color_g'] = dataframe['couleur_dominante'].apply(\n",
    "    lambda x: x[1] if isinstance(x, list) else 0)\n",
    "dataframe['dominant_color_b'] = dataframe['couleur_dominante'].apply(\n",
    "     lambda x: x[2] if isinstance(x, list) else 0)\n",
    "\n",
    "all_final_df = pd.concat([\n",
    "    tags_df,\n",
    "    format_df,\n",
    "    orientation_df,\n",
    "    dataframe[['aire_image', 'dominant_color_r', 'dominant_color_g', 'dominant_color_b']]\n",
    "    ], axis=1)\n",
    "\n",
    "dataframe_evalue = dataframe[dataframe['favori'] != 'n/a']\n",
    "dataframe_non_evalue = dataframe[dataframe['favori'] == 'n/a']\n",
    "\n",
    "labels_evalue = dataframe_evalue['favori'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "X_train = all_final_df.loc[dataframe_evalue.index]\n",
    "y_train = labels_evalue\n",
    "\n",
    "X_test = all_final_df.loc[dataframe_non_evalue.index]\n",
    "\n",
    "\n",
    "svc = SVC(probability=True)\n",
    "perceptron = Perceptron()\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "svc.fit(X_train, y_train)\n",
    "perceptron.fit(X_train, y_train)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predictions_tree = decision_tree.predict(X_test)\n",
    "indices_liked = np.where(predictions_tree == 1)[0]\n",
    "top_n = 10\n",
    "recommended_indices = indices_liked[:top_n]\n",
    "recommended_images = dataframe_non_evalue.iloc[recommended_indices]['nom'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b9561ce1f06790",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Affichage des images recommandées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3bf822681e45ed",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import GridspecLayout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63728a3155996a1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layout = GridspecLayout(n_columns=4, n_rows=len(recommended_images)//4+1, width='1000px')\n",
    "\n",
    "for i, img in enumerate(recommended_images):\n",
    "    file = open(\"images/unsplash-images-collection/\" + img, \"rb\")\n",
    "    image = file.read()\n",
    "    image_widget = widgets.Image(\n",
    "        value=image,\n",
    "        format='png',\n",
    "        width=100,\n",
    "        height=100,\n",
    "    )\n",
    "    layout[i//4, i%4] = image_widget\n",
    "\n",
    "display(layout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
